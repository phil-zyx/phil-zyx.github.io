[{"content":"脑暴想法的由来  话题来自知乎，从而衍生的想法，记录下来 游戏服务器开发属于游戏开发鄙视链底端？ 米哈游出品的原神，告诉了游戏服务器开发一个事情，策划+客户端+美术出品的若服务器游戏模式也可以相当成功。是不是随着原神模式的发展，游戏服务器开发这个岗位需求将越来越少？ chatGPT 这把火越烧越大，游戏服务器开发能集成进游戏服务端去吗？游戏服务器开发能不能造就现象级的，对游戏具备影响的东西呢？  自问自答  游戏服务器开发是不是在鄙视链末端，这点有待商榷，就当前SLG游戏来说，作为打工人的同事，策划or运营，都认为自己在末端。技术无边界，这里的出发点是单纯从游戏来说，游戏的核心是玩法和表现，这里最重要的是策划、客户端、美术，这些东西是直接影响到玩家的，作为一个游戏玩家，不会直观的了解到服务器，这也说明服务器对游戏的影响很小。如此，服务器开发确实在一个末端。 最近刷到原神又成为了收入榜头名，原神模式是不是真的可以抄作业呢？我认为不可。从游戏收入排行榜来看，此模式仅此一家，此类游戏的市场份额极小。同榜单的王者、PUBG等模式仍然是主流，这类和服务器强交互的游戏依然是市场的大头。原神模式会带动一些厂商往这个方向靠，但是赛道依然是各种游戏品类共进的，大部分游戏品类，是无法脱离服务器的。 特别是openAI开放了接口之后，各类chatGPT衍生的项目如雨后春笋般。有些让人眼前一亮的，如chatPDF、自建的自动客服等。那么对于游戏来说，有哪些地方可以接入：对话NPC、游戏内的自动客服、游戏玩法介绍问答等。而现象级的，我想应该是真正的AI，比如引导机器人、对战机器人，可以做到有边界，也有训练，真正做到玩家无法感知其是否是人机。  一些思考  开发不应该设置技术壁垒。具体的说游戏服务器开发和后端开发，客户端开发只是技术侧重点差别而已，其技术本身并没有太大的差别，程序始终都应该保持对技术本身的追求。 如果有想要做独立游戏的想法，那么技术无边界也引导自身去学习客户端开发。AI的发展，像是图像生成已经变得相当可行，做产品会比之前更加简单，我们要去成为站在巨人肩膀上的人。 畅想未来游戏服务器是怎么样的？   云与云计算 AI像真实玩家一样 云游戏，随时随地3A大作 脑机接口 and VR：像《游戏玩家》一样的游戏  ","permalink":"https://Phil-zyx.github.io/posts/gameserverprogrammer/","summary":"脑暴想法的由来  话题来自知乎，从而衍生的想法，记录下来 游戏服务器开发属于游戏开发鄙视链底端？ 米哈游出品的原神，告诉了游戏服务器开发一个事情，策划+客户端+美术出品的若服务器游戏模式也可以相当成功。是不是随着原神模式的发展，游戏服务器开发这个岗位需求将越来越少？ chatGPT 这把火越烧越大，游戏服务器开发能集成进游戏服务端去吗？游戏服务器开发能不能造就现象级的，对游戏具备影响的东西呢？  自问自答  游戏服务器开发是不是在鄙视链末端，这点有待商榷，就当前SLG游戏来说，作为打工人的同事，策划or运营，都认为自己在末端。技术无边界，这里的出发点是单纯从游戏来说，游戏的核心是玩法和表现，这里最重要的是策划、客户端、美术，这些东西是直接影响到玩家的，作为一个游戏玩家，不会直观的了解到服务器，这也说明服务器对游戏的影响很小。如此，服务器开发确实在一个末端。 最近刷到原神又成为了收入榜头名，原神模式是不是真的可以抄作业呢？我认为不可。从游戏收入排行榜来看，此模式仅此一家，此类游戏的市场份额极小。同榜单的王者、PUBG等模式仍然是主流，这类和服务器强交互的游戏依然是市场的大头。原神模式会带动一些厂商往这个方向靠，但是赛道依然是各种游戏品类共进的，大部分游戏品类，是无法脱离服务器的。 特别是openAI开放了接口之后，各类chatGPT衍生的项目如雨后春笋般。有些让人眼前一亮的，如chatPDF、自建的自动客服等。那么对于游戏来说，有哪些地方可以接入：对话NPC、游戏内的自动客服、游戏玩法介绍问答等。而现象级的，我想应该是真正的AI，比如引导机器人、对战机器人，可以做到有边界，也有训练，真正做到玩家无法感知其是否是人机。  一些思考  开发不应该设置技术壁垒。具体的说游戏服务器开发和后端开发，客户端开发只是技术侧重点差别而已，其技术本身并没有太大的差别，程序始终都应该保持对技术本身的追求。 如果有想要做独立游戏的想法，那么技术无边界也引导自身去学习客户端开发。AI的发展，像是图像生成已经变得相当可行，做产品会比之前更加简单，我们要去成为站在巨人肩膀上的人。 畅想未来游戏服务器是怎么样的？   云与云计算 AI像真实玩家一样 云游戏，随时随地3A大作 脑机接口 and VR：像《游戏玩家》一样的游戏  ","title":"游戏服务器开发的未来？"},{"content":" 先思考一个问题：\ngo team 说我们可以创建成千上万个 goroutine 用于处理并发，那么我们还需要 goroutine pool 吗？\ngo team 这么说的底气在于其调度模型 G-P-M，确实\n但是，没有什么是绝对的，比如100w goroutines or more and more\n那么一旦 goroutine 数量过多就会导致资源侵占，CPU暴涨，那么怎么办？\n池化! 复用goroutine\n ants是一个高性能的协程池，实现了对大规模goroutine的调度管理、goroutine复用，允许使用者在开发并发程序的时候限制协程数量，复用资源，达到更高效执行任务的效果。\n提纲  池化技术 ants 如何在项目中使用 *ants 代码设计 学习到的优秀源码  池化技术 池化技术是一种通过创建池子来提高对象复用的常用技术，减少重复创建、销毁的开销。常用池化技术有内存池、对象池、线程池、连接池等。在go语言，goroutine的复用可以理解为线程池技术。ants是一个优秀的代码库，被广泛用于生产环境。\nants 的使用  在其官方的README文件有详细的用法说明，这里简单介绍下基础使用\n p, err := ants.NewPool(workerNum) if err != nil { // 错误处理 } defer p.Release() // 关闭时释放 // 工作任务 worker := func() { xxx } // 提交任务 err := p.Submit(worker) if err != nil { // 错误处理 } 代码设计   核心代码结构\n|-- pool.go |-- worker.go   核心数据结构\ntype Pool struct { // 协程池的容量 \tcapacity int32 // 每个 worker 的过期时间  expiryDuration time.Duration // 存放可使用的worker \tworkers []*Worker } type Worker struct { // 所属的 pool \tpool *Pool // job \ttask chan func() // 被重新放回pool时更新 \trecycleTime time.Time }   核心逻辑代码，隐藏了一些细节，关注宏观实现\n// NewUltimatePool 生成带有自定义定时任务的协程池实例 func NewUltimatePool(size, expiry int, preAlloc bool) (*Pool, error) { var p *Pool // 是否预先分配 \tif preAlloc { p = \u0026amp;Pool{ capacity: int32(size), expiryDuration: time.Duration(expiry) * time.Second, workers: make([]*Worker, 0, size), } } else { p = \u0026amp;Pool{ capacity: int32(size), expiryDuration: time.Duration(expiry) * time.Second, } } // 运行一个goroutine用于tick，回收过期的worker \tgo p.periodicallyPurge() return p, nil } // Submit 提交一个任务 func (p *Pool) Submit(task func()) error { if w := p.retrieveWorker(); w == nil { // 没有空闲 worker \treturn ErrPoolOverload } else { w.task \u0026lt;- task } return nil } // retrieveWorker 返回一个空闲worker运行task func (p *Pool) retrieveWorker() *Worker { var w *Worker spawnWorker := func() { ... 省略 cacheWorker w = \u0026amp;Worker{ pool: p, task: make(chan func(), workerChanCap), } w.run() } p.lock.Lock() idleWorkers := p.workers n := len(idleWorkers) - 1 if n \u0026gt;= 0 { // 从队尾拿出 \tw = idleWorkers[n] idleWorkers[n] = nil p.workers = idleWorkers[:n] p.lock.Unlock() } else if p.Running() \u0026lt; p.Cap() { p.lock.Unlock() spawnWorker() } else { // 阻塞情况会自旋等待获取一个worker，非阻塞则 return \t... } return w } // 执行函数调用 func (w *Worker) run() { go func() { ... panicHandle for f := range w.task { if f == nil { w.pool.decRunning() w.pool.workerCache.Put(w) return } // 执行任务 \tf() // 回收worker \tif ok := w.pool.revertWorker(w); !ok { break } } }() }   总结  ants 池化核心——让一个 goroutine 多处理几个任务。 ants 的实现和我们的线程池不一样，线程池是创建一定数量的线程，阻塞等待任务；而ants之所以不用这么做，是因为基于go G-P-M调度器，只需要限制goroutine数量，尽可能的复用goroutine。 这段代码读起来比较简单，对于培养代码阅读习惯有帮助。  参考资料  仓库地址 手撸高性能groutine pool  ","permalink":"https://Phil-zyx.github.io/posts/%E8%AF%BBants%E6%BA%90%E7%A0%81%E7%90%86%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0/","summary":"先思考一个问题：\ngo team 说我们可以创建成千上万个 goroutine 用于处理并发，那么我们还需要 goroutine pool 吗？\ngo team 这么说的底气在于其调度模型 G-P-M，确实\n但是，没有什么是绝对的，比如100w goroutines or more and more\n那么一旦 goroutine 数量过多就会导致资源侵占，CPU暴涨，那么怎么办？\n池化! 复用goroutine\n ants是一个高性能的协程池，实现了对大规模goroutine的调度管理、goroutine复用，允许使用者在开发并发程序的时候限制协程数量，复用资源，达到更高效执行任务的效果。\n提纲  池化技术 ants 如何在项目中使用 *ants 代码设计 学习到的优秀源码  池化技术 池化技术是一种通过创建池子来提高对象复用的常用技术，减少重复创建、销毁的开销。常用池化技术有内存池、对象池、线程池、连接池等。在go语言，goroutine的复用可以理解为线程池技术。ants是一个优秀的代码库，被广泛用于生产环境。\nants 的使用  在其官方的README文件有详细的用法说明，这里简单介绍下基础使用\n p, err := ants.NewPool(workerNum) if err != nil { // 错误处理 } defer p.Release() // 关闭时释放 // 工作任务 worker := func() { xxx } // 提交任务 err := p.","title":"读ants源码，理解goroutine pool"},{"content":"go语言为什么能变的如此受欢迎，很大一个原因是其原生支持高并发，而这核心来自goroutine的设计，而对goroutine的管理则离不开go的调度器。\n调度的定义  要理解调度，就必要先理解操作系统、进程、线程等调度的基本概念。\n  操作系统：一种计算机程序，管理硬件与软件资源，计算机系统的\u0026quot;底层软件\u0026quot;，如windows,macOS,Linux 进程：操作系统下程序运行单位，有独立的内存，由内核调度 线程：操作系统调度最小单元，一般属于进程，共享进程的内存与资源，由内核调度（比进程轻量） 协程：用户级线程，不由内核调度，通过程序员显示的调度（比线程轻量） 调度：调度本质上就是一个资源分配算法。  Go 调度设计  goroutine 和线程的关系即一个main函数创建一个操作线程——主线程，之后会由go的调度模型来负责创建和管理 goroutine 分配到具体哪个线程.\n 历史  最简单的调度器（Go 0.x）：单线程 G-M：缺陷是程序只能存在一个活跃线程 改进为多线程（Go 1.0）：G-M：互斥锁带来的开销 进阶版本（Go 1.2 至今）：G-P-M：多了一层P抽象  G-P-M   定义：src/runtime/runtime2.go\n  G：goroutine，需要绑定一个 m 来运行\ntype g struct { ... m *m // current m; offset known to arm liblink  preempt bool // 抢占标记  stackguard0 uintptr //  ... }   P：processor, a resource that is required to execute Go code.中间层，G绑定到P才能被M调度\ntype p struct { ... runq [256]guintptr // 环形队列  ... }   M：worker thread, or machine.操作系统抽象线程，负责调度，从P获取G执行\ntype m struct { g0 *g // goroutine with scheduling stack ... curg *g // current running goroutine p puintptr // attached p for executing go code (nil if not executing go code) nextp puintptr oldp puintptr // the p that was attached before executing a syscall  ... }     调度模型\n   调度流程：src/runtime/proc.go   宏观白话文：M和P绑定，不断地从P的队列里面取出G运行，当P的队列没有G了，工作狂M还会从global队列获取G（转移一部分到P的队列）来执行，如果global也没有，M还会从其他的P窃取。 show me the code: 核心代码就是如何获取g，findRunnable  // 找到一个可运行的 goroutine 来执行。 // 尝试从其他 P 窃取，从本地或全局队列中获取 g，轮询网络。 // tryWakeP 表示返回的goroutine不正常(GC worker, trace reader) 所以调用者应该尝试唤醒一个 P。 func findRunnable() (gp *g, inheritTime, tryWakeP bool) { _g_ := getg() top: _p_ := _g_.m.p.ptr() ... // 忽略 gc 相关  // local runq \tif gp, inheritTime := runqget(_p_); gp != nil { return gp, inheritTime, false } // global runq \tif sched.runqsize != 0 { lock(\u0026amp;sched.lock) gp := globrunqget(_p_, 0) unlock(\u0026amp;sched.lock) if gp != nil { return gp, false, false } } ... // 忽略网络轮询器相关  // Spinning Ms：窃取其他 Ps 的工作。  // 限制旋转 Ms 的数量为忙碌 Ps 数量的一半。  // 这是防止 CPU 消耗过多的必要条件  // GOMAXPROCS\u0026gt;\u0026gt;1 但程序并行度低。 \tprocs := uint32(gomaxprocs) if _g_.m.spinning || 2*atomic.Load(\u0026amp;sched.nmspinning) \u0026lt; procs-atomic.Load(\u0026amp;sched.npidle) { if !_g_.m.spinning { _g_.m.spinning = true atomic.Xadd(\u0026amp;sched.nmspinning, 1) } gp, inheritTime, tnow, w, newWork := stealWork(now) now = tnow if gp != nil { // Successfully stole. \treturn gp, inheritTime, false } if newWork { // There may be new timer or GC work; restart to \t// discover. \tgoto top } if w != 0 \u0026amp;\u0026amp; (pollUntil == 0 || w \u0026lt; pollUntil) { // Earlier timer to wait for. \tpollUntil = w } } ... // 实在无事可做，drop P } 阻塞与抢占  阻塞是指当前的G因为一些操作，如系统调用，需要等待，此时M未被利用情况\n抢占是指一个G在没有阻塞情况下执行占用M的时间过长，其他G得不到执行，其他G需要抢占M来获得执行\n 抢占式调度  操作系统的调度是时间片，而go没有该设计，go是通过sysmon的监控程序来实现的。\n   sysmon: src/runtime/proc.go:5134\n// 不需要绑定P运行 func sysmon() { ... for { // 20us - 10ms 唤醒一次  usleep(delay) ... // 重新获取在系统调用中阻塞的 P  // 并抢占长时间运行的 G \tif retake(now) != 0 { idle = 0 } else { idle++ } ... } } func retake(now int64) uint32 { ... s := _p_.status sysretake := false if s == _Prunning || s == _Psyscall { // 如果P运行时间过长则抢占 \tt := int64(_p_.schedtick) if int64(pd.schedtick) != t { pd.schedtick = uint32(t) pd.schedwhen = now } else if pd.schedwhen+forcePreemptNS \u0026lt;= now { preemptone(_p_) // 在 goroutine 上标记 gp.preempt = true \t// In case of syscall, preemptone() doesn\u0026#39;t \t// work, because there is no M wired to P. \tsysretake = true } } ... }   阻塞情况下的调度   syscall\n如果G被阻塞在某个system call操作上，那么不光G会阻塞，执行该G的M也会解绑P(实质是被sysmon抢走了)，与G一起进入sleep状态。如果此时有idle的M，则P与该M绑定继续执行其他G；如果没有idle M，但仍然有其他G要去执行，那么就会创建一个新M。当阻塞在syscall上的G完成syscall调用后，G会去尝试获取一个可用的P，如果没有可用的P，那么G会被标记为runnable，之前的那个sleep的M将再次进入sleep。\n  channel 或 network I/O\n如果G被阻塞在某个channel操作或network I/O操作上时，G会被放置到某个wait队列中，而M会尝试运行下一个runnable的G；如果此时没有runnable的G供m运行，那么m将解绑P，并进入sleep状态。当I/O available或channel操作完成，在wait队列中的G会被唤醒，标记为runnable，放入到某P的队列中，绑定一个M继续执行。\n  其他的调度方式  NUMA调度提议  ###调度器在Go中如何运行\n要理解调度器，仅仅知道G-P-M还不够，还需要了解完整的调度流程，调度器的初始化、goroutine的添加等等，这一块会再去读一读源码，理解一下。\n在工作中的使用  工作中总是充满了CURD，我常常迷惑于了解了这些知识有什么作用，我又该如何应用。\n   了解调度，我们才能知道该如何在应用中去使用 goroutine，goroutine 虽然轻量，但也不是越多越好。\n  遇到一些问题时，我们可以通过查看调度来思考代码的优化方案。\n  如何查看go调度器：通过GODEBUG运行时环境变量的schedtrace=1000参数，可以每隔1000ms查看一次调度器状态。\nGODEBUG=schedtrace=1000 ./main 打印 SCHED 1007ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=5 runqueue=0 [0 0 0 0] SCHED 2011ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=5 runqueue=0 [0 0 0 0] 参数含义 gomaxprocs: P的数量； idleprocs: 处于idle状态的P的数量；通过gomaxprocs和idleprocs的差值，我们就可知道执行go代码的P的数量； threads: os threads的数量，包含scheduler使用的m数量，加上runtime自用的类似sysmon这样的thread的数量； spinningthreads: 处于自旋状态的os thread数量； idlethread: 处于idle状态的os thread的数量； runqueue： go scheduler全局队列中G的数量； [0 0 0 0]: 分别为4个P的local queue中的G的数量。   总结  go 调度经历过几个版本，很巧妙的地方就是中间层P的抽象，很多设计的核心都很简单，但是其最迷人的地方就是抽象。 很多文章都讲过G-P-M调度，内容其实大同小异，在写这篇博文的时候，去翻看了源码，其实这些东西都在代码里，且有很好的注释。  相关资料   《Go 语言设计与实现》—— 左神\n  Go 调度模型——wudaijun\u0026rsquo;s blog\n  ","permalink":"https://Phil-zyx.github.io/posts/%E5%AF%B9go%E8%B0%83%E5%BA%A6%E7%9A%84%E6%B5%85%E8%AF%BB/","summary":"go语言为什么能变的如此受欢迎，很大一个原因是其原生支持高并发，而这核心来自goroutine的设计，而对goroutine的管理则离不开go的调度器。\n调度的定义  要理解调度，就必要先理解操作系统、进程、线程等调度的基本概念。\n  操作系统：一种计算机程序，管理硬件与软件资源，计算机系统的\u0026quot;底层软件\u0026quot;，如windows,macOS,Linux 进程：操作系统下程序运行单位，有独立的内存，由内核调度 线程：操作系统调度最小单元，一般属于进程，共享进程的内存与资源，由内核调度（比进程轻量） 协程：用户级线程，不由内核调度，通过程序员显示的调度（比线程轻量） 调度：调度本质上就是一个资源分配算法。  Go 调度设计  goroutine 和线程的关系即一个main函数创建一个操作线程——主线程，之后会由go的调度模型来负责创建和管理 goroutine 分配到具体哪个线程.\n 历史  最简单的调度器（Go 0.x）：单线程 G-M：缺陷是程序只能存在一个活跃线程 改进为多线程（Go 1.0）：G-M：互斥锁带来的开销 进阶版本（Go 1.2 至今）：G-P-M：多了一层P抽象  G-P-M   定义：src/runtime/runtime2.go\n  G：goroutine，需要绑定一个 m 来运行\ntype g struct { ... m *m // current m; offset known to arm liblink  preempt bool // 抢占标记  stackguard0 uintptr //  ... }   P：processor, a resource that is required to execute Go code.","title":"对go调度的浅读"},{"content":" 最近工作上做了一些关于跨服玩法的内容，对于 RPC 通信实现这块做下学习笔记整理。\n 分布式架构 当下的大环境下，服务器架构基本都是分布式架构。分布式架构带来的最大好处在于服务扩展，我们 SLG 游戏服务器从游戏特性上来说，符合小服架构（一个服即一个生态），这样从分布式架构的设计理念，按功能划分，网关、支付、战场（这里不是指单服的战斗要实现一个节点，而是一些副本玩法，跨服玩法等设计的）、第三方等，这样的每个 server 我们称之为一个节点（Node）。\nRPC RPC:允许运行于一台计算机的程序调用另一个计算机的程序。RPC是一种服务器-客户端（Client/Server）模式。\nRPC 的核心概念即调用远程服务就像调用本地的一个函数一样简单。\n通过原理我们知道 RPC 需要实现的几个点:\n 通信：在两个 server 之间建立连接 寻址：如何定位需要调用 x-Server 序列化：两个 server 之间是网络通信，那么二进制传输就需要序列化  一些常用的框架（轮子必然是有的）：\n gRPC: 谷歌开源 RPC 框架，基于 HTTP/2 协议通信和 ProtoBuf 序列化协议 Thrift: Apache 旗下，基于 Facebook 的 RPC 框架开发 JsonRPC: 无状态、轻量级，基于 json 序列化  框架选择：两个项目，早期的一个选择 thrift （当时 gRPC 才开源初期），另一个选择了 gRPC ，对比来说，两者在使用上区别不是很大，但是 gRPC 能拥有良好的文档，更加简洁和拥有广泛使用的 ProtoBuf，而 thrift 的大优势是支持多语言。选择根据项目自身的特性来，对于我们项目，文档和简洁比较重要。（技术选型还得是项目初始大佬们的选择:joy:）\n节点间通信 如上，RPC 框架选择 gRPC，基于此，整个通信流程：\nclient -\u0026gt; gateway -\u0026gt; game server -\u0026gt; other server -\u0026gt; 处理后返回\n游戏服务器一般选择长连接，因为游戏特性：交互频繁，数据量大。RPC 当然也有这种特性，所以 gRPC 也支持一次调用一次创建和流式（stream）调用两种方式，这个根据业务的情况进行处理。client 与 game server 的通信采用了双向 steam 方式，client 通过和 gate 建立 tcp 连接（一个 agent），然后通过 LoginReq 来创建和 game server 的流式管道（中间还有玩家信息验证服交互，目标服务器 check 等操作 | 目标服的 connect 信息通过 etcd 获取， etcd 做服务发现和管理），每个 agent 本身会有一个 pipe mgr 来管理这些创建的管道，用于和不同的 server 之间进行消息收发。这样就建立起 client \u0026lt;—\u0026gt; game server 的通信连接。\n既然节点间的通信就是 client/server 的模式，那么 game server 和 battle server 之间的服务调用也就差别不大。以此为例，简述我们 gs 和 bs 之间的服务调用：\n 一次调用：gRPC Asyn Call 调用 bs 的服务器，通过异步回调返回执行的数据，并处理返还给 client steam: 每个 server 都有一个自己的 gate mgr 用于管理 RPC 消息通信和 agent data，首次调用 bs 服务时创建一个 steam 连接，后面调用直接 sendMsg 没有玩家 agent 的 stream 调用：每个 server 都创建一个 owner agent 并且在需要的时候和目标 server 之间建立一个 steam pipe，来完成多次调用  举例说明：\n我现在有个副本玩法，需要开房间实现 pvp：\n-\u0026gt; clientA 通过 loginBattleReq 创建和 bs 的 steam 连接，并且在 bs 开启一个房间\n-\u0026gt; clientB 通过 joinBattleReq 同样创建一个 stream 连接，加入到 A 的房间\n-\u0026gt; 然后 bs 房间业务逻辑执行，A vs B 战斗开始\n-\u0026gt; SLG 的一个特性，不同于 moba 游戏玩法，这里业务上可能多个玩家要持续一段时间 pvp 获得积分，在结束时，玩家可能已经不在线，steam 和 agent 也销毁了，结算信息传递给 gs 就需要通过 owner agent 来实现了。由此，一个完整的节点通信模型就实现了。\n总结  目前的这套架构实现比较简单，弱耦合单向依赖 gRPC call、强耦合双向依赖 stream，已经能满足当下的基本需求，其次在编码方面做了一些封装，对于开发人员来说比较方便。 当需求变化伴随节点细分变多，耦合变重，那么网络拓扑也会变成一个问题，这种情况下的 steam 就不能很好的胜任。  ","permalink":"https://Phil-zyx.github.io/posts/%E6%BC%AB%E8%B0%88%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%8A%82%E7%82%B9%E9%80%9A%E4%BF%A1/","summary":"最近工作上做了一些关于跨服玩法的内容，对于 RPC 通信实现这块做下学习笔记整理。\n 分布式架构 当下的大环境下，服务器架构基本都是分布式架构。分布式架构带来的最大好处在于服务扩展，我们 SLG 游戏服务器从游戏特性上来说，符合小服架构（一个服即一个生态），这样从分布式架构的设计理念，按功能划分，网关、支付、战场（这里不是指单服的战斗要实现一个节点，而是一些副本玩法，跨服玩法等设计的）、第三方等，这样的每个 server 我们称之为一个节点（Node）。\nRPC RPC:允许运行于一台计算机的程序调用另一个计算机的程序。RPC是一种服务器-客户端（Client/Server）模式。\nRPC 的核心概念即调用远程服务就像调用本地的一个函数一样简单。\n通过原理我们知道 RPC 需要实现的几个点:\n 通信：在两个 server 之间建立连接 寻址：如何定位需要调用 x-Server 序列化：两个 server 之间是网络通信，那么二进制传输就需要序列化  一些常用的框架（轮子必然是有的）：\n gRPC: 谷歌开源 RPC 框架，基于 HTTP/2 协议通信和 ProtoBuf 序列化协议 Thrift: Apache 旗下，基于 Facebook 的 RPC 框架开发 JsonRPC: 无状态、轻量级，基于 json 序列化  框架选择：两个项目，早期的一个选择 thrift （当时 gRPC 才开源初期），另一个选择了 gRPC ，对比来说，两者在使用上区别不是很大，但是 gRPC 能拥有良好的文档，更加简洁和拥有广泛使用的 ProtoBuf，而 thrift 的大优势是支持多语言。选择根据项目自身的特性来，对于我们项目，文档和简洁比较重要。（技术选型还得是项目初始大佬们的选择:joy:）\n节点间通信 如上，RPC 框架选择 gRPC，基于此，整个通信流程：\nclient -\u0026gt; gateway -\u0026gt; game server -\u0026gt; other server -\u0026gt; 处理后返回","title":"漫谈游戏服务器节点通信"},{"content":" 题目：循环按序打印\u0026quot;dog\u0026quot;、\u0026ldquo;cat\u0026rdquo;、fish\u0026quot;，分别使用三个 goroutine.\n 拿到题目，感觉简单又不简单的样子，先动手写一个最简单的打印：\nfunc main() { times := 100 go func() { for i := 0; i\u0026lt;times; i++ { println(\u0026#34;dog\u0026#34;) println(\u0026#34;cat\u0026#34;) println(\u0026#34;fish\u0026#34;) } }() time.Sleep(100 * 1000) // 这时间我能算出来么，那用 channel 来接收吧 } 改进一下这让人无法预估的等待时间：使用 channel，在 goroutine 执行完之后通知主程序，巩固依稀 gorutine 和 channel 的基础知识：\n gorutine 是并发核心，main 函数也是一个 gorutine go func() {}() 匿名函数要注意参数传入 channel 通过 make 创建，make(chan typ) 需要声明好类型 channel 通过 \u0026lt;-ch ch \u0026lt;- data 来接收和发送信息 channel make(ch, int, 1 表示该 ch 是一个有1个数据缓冲的 chan，即在没有接收数据的情况下，第二条数据发送之后才会阻塞 func (ch chan \u0026lt;- int) 声明 ch 是一个单向 channel close后的 chan 依然可以接收缓冲通道的数据，但不可发送数据 select {case \u0026lt;- ch: xx} 处理不同消息  func main() { waitCh := make(chan struct{}, 1) times := 100 go func() { for i := 0; i \u0026lt; times; i++ { println(\u0026#34;dog\u0026#34;) println(\u0026#34;cat\u0026#34;) println(\u0026#34;fish\u0026#34;) } waitCh \u0026lt;- struct{}{} }() \u0026lt;-waitCh } waitCh 听起来怎么这么熟悉呢？go 本身在面对这些情况已经实现了一个工具类，sync 包中提供的基础原语： waitGroup 。巩固一下：\n 官方描述：一个 WaitGroup 对象可以等待一组协程结束 我们可以通过 sync.WaitGroup 将原本顺序执行的代码在多个 Goroutine 中并发执行，加快程序处理的速度。 该类暴露三个接口：add wait done 废话别说，show me the code 🙂  func main() { wg := sync.WaitGroup{} times := 100 wg.Add(1) // 协程数 \tgo func() { for i := 0; i \u0026lt; times; i++ { println(\u0026#34;dog\u0026#34;) println(\u0026#34;cat\u0026#34;) println(\u0026#34;fish\u0026#34;) } wg.Done() // 协程执行完毕，一般复杂业务会有容错，确保执行： defer wg.Done() \t}() wg.Wait() } 实现三个直接打印的 goroutine 必然不能保证有序，那就必须在 goroutine 间通信，cha -\u0026gt; chb -\u0026gt; chc-\u0026gt;cha 循环触发则可以实现该功能。\nfunc main() { wg := sync.WaitGroup{} wg.Add(3) dogCh := make(chan struct{}, 1) catCh := make(chan struct{}, 1) fishCh := make(chan struct{}, 1) times := 10 dogCounter, catCounter, fishCounter := 0, 0, 0 go PrintTheVal(dogCh, catCh, dogCounter, times, \u0026amp;wg, \u0026#34;dog\u0026#34;) // \u0026amp;wg 需要取地址 \tgo PrintTheVal(catCh, fishCh, catCounter, times, \u0026amp;wg, \u0026#34;cat\u0026#34;) go PrintTheVal(fishCh, dogCh, fishCounter, times, \u0026amp;wg, \u0026#34;fish\u0026#34;) dogCh \u0026lt;- struct{}{} wg.Wait() } func PrintTheVal(selfCh, toCh chan struct{}, counter, max int, wg *sync.WaitGroup, val string) { for { \u0026lt;- selfCh toCh \u0026lt;- struct{}{} if counter \u0026gt;= max { wg.Done() return } println(val) counter++ } } 总结  通过简单的题目能快速理解基础语法，也能在实现简单题目中发现不足和巩固基础。 发散思维：其他同步原语的使用？  ","permalink":"https://Phil-zyx.github.io/posts/%E4%B8%80%E9%81%93go%E7%BC%96%E7%A8%8B%E9%A2%98%E7%9A%84%E5%8F%8D%E6%80%9D/","summary":"题目：循环按序打印\u0026quot;dog\u0026quot;、\u0026ldquo;cat\u0026rdquo;、fish\u0026quot;，分别使用三个 goroutine.\n 拿到题目，感觉简单又不简单的样子，先动手写一个最简单的打印：\nfunc main() { times := 100 go func() { for i := 0; i\u0026lt;times; i++ { println(\u0026#34;dog\u0026#34;) println(\u0026#34;cat\u0026#34;) println(\u0026#34;fish\u0026#34;) } }() time.Sleep(100 * 1000) // 这时间我能算出来么，那用 channel 来接收吧 } 改进一下这让人无法预估的等待时间：使用 channel，在 goroutine 执行完之后通知主程序，巩固依稀 gorutine 和 channel 的基础知识：\n gorutine 是并发核心，main 函数也是一个 gorutine go func() {}() 匿名函数要注意参数传入 channel 通过 make 创建，make(chan typ) 需要声明好类型 channel 通过 \u0026lt;-ch ch \u0026lt;- data 来接收和发送信息 channel make(ch, int, 1 表示该 ch 是一个有1个数据缓冲的 chan，即在没有接收数据的情况下，第二条数据发送之后才会阻塞 func (ch chan \u0026lt;- int) 声明 ch 是一个单向 channel close后的 chan 依然可以接收缓冲通道的数据，但不可发送数据 select {case \u0026lt;- ch: xx} 处理不同消息  func main() { waitCh := make(chan struct{}, 1) times := 100 go func() { for i := 0; i \u0026lt; times; i++ { println(\u0026#34;dog\u0026#34;) println(\u0026#34;cat\u0026#34;) println(\u0026#34;fish\u0026#34;) } waitCh \u0026lt;- struct{}{} }() \u0026lt;-waitCh } waitCh 听起来怎么这么熟悉呢？go 本身在面对这些情况已经实现了一个工具类，sync 包中提供的基础原语： waitGroup 。巩固一下：","title":"一道GO编程题的反思"},{"content":"2020 即将过去，这一年最大的总结就是：什么目标也没有完成。\n","permalink":"https://Phil-zyx.github.io/posts/summary2020/","summary":"2020 即将过去，这一年最大的总结就是：什么目标也没有完成。","title":"2020 年终总结"},{"content":" 目前从事游戏服务器开发 Gopher 游戏爱好者  最后留个\n QQ：1757163340 Email：zhouyaoxux@gmail.com  ","permalink":"https://Phil-zyx.github.io/aboutme/","summary":"aboutme","title":"About Me"}]