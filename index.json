[{"content":"脑暴想法的由来  话题来自知乎，从而衍生的想法，记录下来 游戏服务器开发属于游戏开发鄙视链底端？ 米哈游出品的原神，告诉了游戏服务器开发一个事情，策划+客户端+美术出品的若服务器游戏模式也可以相当成功。是不是随着原神模式的发展，游戏服务器开发这个岗位需求将越来越少？ chatGPT 这把火越烧越大，游戏服务器开发能集成进游戏服务端去吗？游戏服务器开发能不能造就现象级的，对游戏具备影响的东西呢？  自问自答  游戏服务器开发是不是在鄙视链末端，这点有待商榷，就当前SLG游戏来说，作为打工人的同事，策划or运营，都认为自己在末端。技术无边界，这里的出发点是单纯从游戏来说，游戏的核心是玩法和表现，这里最重要的是策划、客户端、美术，这些东西是直接影响到玩家的，作为一个游戏玩家，不会直观的了解到服务器，这也说明服务器对游戏的影响很小。如此，服务器开发确实在一个末端。 最近刷到原神又成为了收入榜头名，原神模式是不是真的可以抄作业呢？我认为不可。从游戏收入排行榜来看，此模式仅此一家，此类游戏的市场份额极小。同榜单的王者、PUBG等模式仍然是主流，这类和服务器强交互的游戏依然是市场的大头。原神模式会带动一些厂商往这个方向靠，但是赛道依然是各种游戏品类共进的，大部分游戏品类，是无法脱离服务器的。 特别是openAI开放了接口之后，各类chatGPT衍生的项目如雨后春笋般。有些让人眼前一亮的，如chatPDF、自建的自动客服等。那么对于游戏来说，有哪些地方可以接入：对话NPC、游戏内的自动客服、游戏玩法介绍问答等。而现象级的，我想应该是真正的AI，比如引导机器人、对战机器人，可以做到有边界，也有训练，真正做到玩家无法感知其是否是人机。  一些思考  开发不应该设置技术壁垒。具体的说游戏服务器开发和后端开发，客户端开发只是技术侧重点差别而已，其技术本身并没有太大的差别，程序始终都应该保持对技术本身的追求。 如果有想要做独立游戏的想法，那么技术无边界也引导自身去学习客户端开发。AI的发展，像是图像生成已经变得相当可行，做产品会比之前更加简单，我们要去成为站在巨人肩膀上的人。 畅想未来游戏服务器是怎么样的？   云与云计算 AI像真实玩家一样 云游戏，随时随地3A大作 脑机接口 and VR：像《游戏玩家》一样的游戏  ","permalink":"https://Phil-zyx.github.io/posts/gameserverprogrammer/","summary":"脑暴想法的由来  话题来自知乎，从而衍生的想法，记录下来 游戏服务器开发属于游戏开发鄙视链底端？ 米哈游出品的原神，告诉了游戏服务器开发一个事情，策划+客户端+美术出品的若服务器游戏模式也可以相当成功。是不是随着原神模式的发展，游戏服务器开发这个岗位需求将越来越少？ chatGPT 这把火越烧越大，游戏服务器开发能集成进游戏服务端去吗？游戏服务器开发能不能造就现象级的，对游戏具备影响的东西呢？  自问自答  游戏服务器开发是不是在鄙视链末端，这点有待商榷，就当前SLG游戏来说，作为打工人的同事，策划or运营，都认为自己在末端。技术无边界，这里的出发点是单纯从游戏来说，游戏的核心是玩法和表现，这里最重要的是策划、客户端、美术，这些东西是直接影响到玩家的，作为一个游戏玩家，不会直观的了解到服务器，这也说明服务器对游戏的影响很小。如此，服务器开发确实在一个末端。 最近刷到原神又成为了收入榜头名，原神模式是不是真的可以抄作业呢？我认为不可。从游戏收入排行榜来看，此模式仅此一家，此类游戏的市场份额极小。同榜单的王者、PUBG等模式仍然是主流，这类和服务器强交互的游戏依然是市场的大头。原神模式会带动一些厂商往这个方向靠，但是赛道依然是各种游戏品类共进的，大部分游戏品类，是无法脱离服务器的。 特别是openAI开放了接口之后，各类chatGPT衍生的项目如雨后春笋般。有些让人眼前一亮的，如chatPDF、自建的自动客服等。那么对于游戏来说，有哪些地方可以接入：对话NPC、游戏内的自动客服、游戏玩法介绍问答等。而现象级的，我想应该是真正的AI，比如引导机器人、对战机器人，可以做到有边界，也有训练，真正做到玩家无法感知其是否是人机。  一些思考  开发不应该设置技术壁垒。具体的说游戏服务器开发和后端开发，客户端开发只是技术侧重点差别而已，其技术本身并没有太大的差别，程序始终都应该保持对技术本身的追求。 如果有想要做独立游戏的想法，那么技术无边界也引导自身去学习客户端开发。AI的发展，像是图像生成已经变得相当可行，做产品会比之前更加简单，我们要去成为站在巨人肩膀上的人。 畅想未来游戏服务器是怎么样的？   云与云计算 AI像真实玩家一样 云游戏，随时随地3A大作 脑机接口 and VR：像《游戏玩家》一样的游戏  ","title":"游戏服务器开发的未来？"},{"content":"对于一个后端开发者，性能分析及其重要，在Go语言中， 提供了一些优秀的诊断工具来帮助我们深入分析应用程序的执行情况，这些工具中最常用的当属pprof。\n提出问题  Go性能分析要关注什么 pprof 如何使用 pprof分析报告解读  性能分析  CPU：程序对CPU的使用，时间都花在哪里； Heap：堆内存分配及占用内存的情况，是否存在内存泄漏； goroutine：goroutine 运行堆栈信息 Block：阻塞等待信息 Mutex: 锁竞争情况  pprof 使用 开启 pprof   方法一，引入 \u0026ldquo;net/http/pprof\u0026rdquo;\nimport _ \u0026#34;net/http/pprof\u0026#34; 这样我们就可以通过访问http://localhost:6060/debug/pprof来访问pprof\n  方法2，自定义端口及地址\nfunc RunProf(port int) { mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/debug/pprof/\u0026#34;, pprof.Index) mux.HandleFunc(\u0026#34;/debug/pprof/cmdline\u0026#34;, pprof.Cmdline) mux.HandleFunc(\u0026#34;/debug/pprof/profile\u0026#34;, pprof.Profile) mux.HandleFunc(\u0026#34;/debug/pprof/symbol\u0026#34;, pprof.Symbol) mux.HandleFunc(\u0026#34;/debug/pprof/trace\u0026#34;, pprof.Trace) if port != 0 { ip := \u0026#34;localhost\u0026#34; go func() { addr := fmt.Sprintf(\u0026#34;%v:%v\u0026#34;, ip, port) tlog.Infof(\u0026#34;pprof httpserver server listening on: %v\u0026#34;, addr) err := http.ListenAndServe(addr, mux) if err != nil { tlog.Fatal(\u0026#34;pprof httpserver start failed. err: \u0026#34;, err.Error()) } }() } } // 或者在 gin 集成 // RunProf 启动性能监控 func RunProf(r *gin.Engine) { // 将 pprof 与路由器实例关联 \tr.GET(\u0026#34;/debug/pprof/*name\u0026#34;, gin.WrapH(http.DefaultServeMux)) }   获取pprof信息   直接访问网页 http://localhost:port/debug/pprof/，但这类信息是阅读不友好的，所以一般不使用。\n  执行go tool pprof http://localhost:port/debug/pprof/XXX 进入交互界面，输入help，里面有各种方式来查看数据，诸如 web,svg\u0026hellip;\n  生成的pprof分析文件，go tool pprof -seconds=30 http://localhost:port/debug/pprof/profile \u0026gt; cpu.pprof ，我们可以通过-seconds=xx 来设置采样时间，生成文件后可以指定端口在网页查看，比交互界面更直观：go tool pprof -http=:port cup.pprof\n  XXX 参数在 runtime/pprof/pprof.go 定义\n\u0026#34;profile\u0026#34;: cpuProfile, \u0026#34;goroutine\u0026#34;: goroutineProfile, \u0026#34;threadcreate\u0026#34;: threadcreateProfile, \u0026#34;heap\u0026#34;: heapProfile, \u0026#34;allocs\u0026#34;: allocsProfile, \u0026#34;block\u0026#34;: blockProfile, \u0026#34;mutex\u0026#34;: mutexProfile,   看懂性能分析  一般在生产项目中，我们会dump下分析文件，在本地进行分析\n   第一步：go tool pprof -http=:8088 pprof分析文件\n  第二步：web 直接看图\n 当前界面为Graph界面，这个图是采样30s内的CPU使用情况分析，矩形越大说明，线条越粗则证明占用越大   这里截取了最大的矩形，可以从具体的内容看到详细信息，如函数名：scanobject，占用2.01s，占总共7.32s的31.39%，然后还有细分的内容。这里结合go特性，可以得出一个问题：gc扫描占用了很大比重，说明程序中堆上的对象分配过多    另外的常用方式，火焰图 flame graph，top\n 火焰图可以更直观的看出函数的调用栈，同时越宽代表占用越多，此处可以得出同上结论 top 则是列出文字分析信息 如果是直接的交互分析，还还可以通过list func 来查看热点函数具体的代码    在得出了堆上分配对象过多，于是进行了heap采样分析，同理，我们定位到具体的函数，对函数进行逃逸分析，最后对这部分代码进行了优化，减少了对象分配，从而减少了gc占用时间。\n  总结  这里只是简单的描述了pprof的使用，然后结合了一次生产环境的分析经历，记录下如何做pprof性能分析。 作为后端程序，一定要时刻关注性能，了解性能热点，及时对代码进行分析重构。 go 提供了镰刀，我们就要学会当死神。  参考资料  一看就懂系列之Golang的pprof——咖啡色的羊驼  ","permalink":"https://Phil-zyx.github.io/posts/pprof%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C%E6%89%8B%E5%86%8C/","summary":"对于一个后端开发者，性能分析及其重要，在Go语言中， 提供了一些优秀的诊断工具来帮助我们深入分析应用程序的执行情况，这些工具中最常用的当属pprof。\n提出问题  Go性能分析要关注什么 pprof 如何使用 pprof分析报告解读  性能分析  CPU：程序对CPU的使用，时间都花在哪里； Heap：堆内存分配及占用内存的情况，是否存在内存泄漏； goroutine：goroutine 运行堆栈信息 Block：阻塞等待信息 Mutex: 锁竞争情况  pprof 使用 开启 pprof   方法一，引入 \u0026ldquo;net/http/pprof\u0026rdquo;\nimport _ \u0026#34;net/http/pprof\u0026#34; 这样我们就可以通过访问http://localhost:6060/debug/pprof来访问pprof\n  方法2，自定义端口及地址\nfunc RunProf(port int) { mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/debug/pprof/\u0026#34;, pprof.Index) mux.HandleFunc(\u0026#34;/debug/pprof/cmdline\u0026#34;, pprof.Cmdline) mux.HandleFunc(\u0026#34;/debug/pprof/profile\u0026#34;, pprof.Profile) mux.HandleFunc(\u0026#34;/debug/pprof/symbol\u0026#34;, pprof.Symbol) mux.HandleFunc(\u0026#34;/debug/pprof/trace\u0026#34;, pprof.Trace) if port != 0 { ip := \u0026#34;localhost\u0026#34; go func() { addr := fmt.Sprintf(\u0026#34;%v:%v\u0026#34;, ip, port) tlog.Infof(\u0026#34;pprof httpserver server listening on: %v\u0026#34;, addr) err := http.","title":"Go pprof使用之记录一次项目中的分析"},{"content":" 先思考一个问题：\ngo team 说我们可以创建成千上万个 goroutine 用于处理并发，那么我们还需要 goroutine pool 吗？\ngo team 这么说的底气在于其调度模型 G-P-M，确实\n但是，没有什么是绝对的，比如100w goroutines or more and more\n那么一旦 goroutine 数量过多就会导致资源侵占，CPU暴涨，那么怎么办？\n池化! 复用goroutine\n ants是一个高性能的协程池，实现了对大规模goroutine的调度管理、goroutine复用，允许使用者在开发并发程序的时候限制协程数量，复用资源，达到更高效执行任务的效果。\n提纲  池化技术 ants 如何在项目中使用 *ants 代码设计 学习到的优秀源码  池化技术 池化技术是一种通过创建池子来提高对象复用的常用技术，减少重复创建、销毁的开销。常用池化技术有内存池、对象池、线程池、连接池等。在go语言，goroutine的复用可以理解为线程池技术。ants是一个优秀的代码库，被广泛用于生产环境。\nants 的使用  在其官方的README文件有详细的用法说明，这里简单介绍下基础使用\n p, err := ants.NewPool(workerNum) if err != nil { // 错误处理 } defer p.Release() // 关闭时释放 // 工作任务 worker := func() { xxx } // 提交任务 err := p.Submit(worker) if err != nil { // 错误处理 } 代码设计   核心代码结构\n|-- pool.go |-- worker.go   核心数据结构\ntype Pool struct { // 协程池的容量 \tcapacity int32 // 每个 worker 的过期时间  expiryDuration time.Duration // 存放可使用的worker \tworkers []*Worker } type Worker struct { // 所属的 pool \tpool *Pool // job \ttask chan func() // 被重新放回pool时更新 \trecycleTime time.Time }   核心逻辑代码，隐藏了一些细节，关注宏观实现\n// NewUltimatePool 生成带有自定义定时任务的协程池实例 func NewUltimatePool(size, expiry int, preAlloc bool) (*Pool, error) { var p *Pool // 是否预先分配 \tif preAlloc { p = \u0026amp;Pool{ capacity: int32(size), expiryDuration: time.Duration(expiry) * time.Second, workers: make([]*Worker, 0, size), } } else { p = \u0026amp;Pool{ capacity: int32(size), expiryDuration: time.Duration(expiry) * time.Second, } } // 运行一个goroutine用于tick，回收过期的worker \tgo p.periodicallyPurge() return p, nil } // Submit 提交一个任务 func (p *Pool) Submit(task func()) error { if w := p.retrieveWorker(); w == nil { // 没有空闲 worker \treturn ErrPoolOverload } else { w.task \u0026lt;- task } return nil } // retrieveWorker 返回一个空闲worker运行task func (p *Pool) retrieveWorker() *Worker { var w *Worker spawnWorker := func() { ... 省略 cacheWorker w = \u0026amp;Worker{ pool: p, task: make(chan func(), workerChanCap), } w.run() } p.lock.Lock() idleWorkers := p.workers n := len(idleWorkers) - 1 if n \u0026gt;= 0 { // 从队尾拿出 \tw = idleWorkers[n] idleWorkers[n] = nil p.workers = idleWorkers[:n] p.lock.Unlock() } else if p.Running() \u0026lt; p.Cap() { p.lock.Unlock() spawnWorker() } else { // 阻塞情况会自旋等待获取一个worker，非阻塞则 return \t... } return w } // 执行函数调用 func (w *Worker) run() { go func() { ... panicHandle for f := range w.task { if f == nil { w.pool.decRunning() w.pool.workerCache.Put(w) return } // 执行任务 \tf() // 回收worker \tif ok := w.pool.revertWorker(w); !ok { break } } }() }   总结  ants 池化核心——让一个 goroutine 多处理几个任务。 ants 的实现和我们的线程池不一样，线程池是创建一定数量的线程，阻塞等待任务；而ants之所以不用这么做，是因为基于go G-P-M调度器，只需要限制goroutine数量，尽可能的复用goroutine。 这段代码读起来比较简单，对于培养代码阅读习惯有帮助。  参考资料  仓库地址 手撸高性能groutine pool  ","permalink":"https://Phil-zyx.github.io/posts/%E8%AF%BBants%E6%BA%90%E7%A0%81%E7%90%86%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0/","summary":"先思考一个问题：\ngo team 说我们可以创建成千上万个 goroutine 用于处理并发，那么我们还需要 goroutine pool 吗？\ngo team 这么说的底气在于其调度模型 G-P-M，确实\n但是，没有什么是绝对的，比如100w goroutines or more and more\n那么一旦 goroutine 数量过多就会导致资源侵占，CPU暴涨，那么怎么办？\n池化! 复用goroutine\n ants是一个高性能的协程池，实现了对大规模goroutine的调度管理、goroutine复用，允许使用者在开发并发程序的时候限制协程数量，复用资源，达到更高效执行任务的效果。\n提纲  池化技术 ants 如何在项目中使用 *ants 代码设计 学习到的优秀源码  池化技术 池化技术是一种通过创建池子来提高对象复用的常用技术，减少重复创建、销毁的开销。常用池化技术有内存池、对象池、线程池、连接池等。在go语言，goroutine的复用可以理解为线程池技术。ants是一个优秀的代码库，被广泛用于生产环境。\nants 的使用  在其官方的README文件有详细的用法说明，这里简单介绍下基础使用\n p, err := ants.NewPool(workerNum) if err != nil { // 错误处理 } defer p.Release() // 关闭时释放 // 工作任务 worker := func() { xxx } // 提交任务 err := p.","title":"读ants源码，理解goroutine pool"},{"content":"go语言为什么能变的如此受欢迎，很大一个原因是其原生支持高并发，而这核心来自goroutine的设计，而对goroutine的管理则离不开go的调度器。\n调度的定义  要理解调度，就必要先理解操作系统、进程、线程等调度的基本概念。\n  操作系统：一种计算机程序，管理硬件与软件资源，计算机系统的\u0026quot;底层软件\u0026quot;，如windows,macOS,Linux 进程：操作系统下程序运行单位，有独立的内存，由内核调度 线程：操作系统调度最小单元，一般属于进程，共享进程的内存与资源，由内核调度（比进程轻量） 协程：用户级线程，不由内核调度，通过程序员显示的调度（比线程轻量） 调度：调度本质上就是一个资源分配算法。  Go 调度设计  goroutine 和线程的关系即一个main函数创建一个操作线程——主线程，之后会由go的调度模型来负责创建和管理 goroutine 分配到具体哪个线程.\n 历史  最简单的调度器（Go 0.x）：单线程 G-M：缺陷是程序只能存在一个活跃线程 改进为多线程（Go 1.0）：G-M：互斥锁带来的开销 进阶版本（Go 1.2 至今）：G-P-M：多了一层P抽象  G-P-M   定义：src/runtime/runtime2.go\n  G：goroutine，需要绑定一个 m 来运行\ntype g struct { ... m *m // current m; offset known to arm liblink  preempt bool // 抢占标记  stackguard0 uintptr //  ... }   P：processor, a resource that is required to execute Go code.中间层，G绑定到P才能被M调度\ntype p struct { ... runq [256]guintptr // 环形队列  ... }   M：worker thread, or machine.操作系统抽象线程，负责调度，从P获取G执行\ntype m struct { g0 *g // goroutine with scheduling stack ... curg *g // current running goroutine p puintptr // attached p for executing go code (nil if not executing go code) nextp puintptr oldp puintptr // the p that was attached before executing a syscall  ... }     调度模型\n   调度流程：src/runtime/proc.go   宏观白话文：M和P绑定，不断地从P的队列里面取出G运行，当P的队列没有G了，工作狂M还会从global队列获取G（转移一部分到P的队列）来执行，如果global也没有，M还会从其他的P窃取。 show me the code: 核心代码就是如何获取g，findRunnable  // 找到一个可运行的 goroutine 来执行。 // 尝试从其他 P 窃取，从本地或全局队列中获取 g，轮询网络。 // tryWakeP 表示返回的goroutine不正常(GC worker, trace reader) 所以调用者应该尝试唤醒一个 P。 func findRunnable() (gp *g, inheritTime, tryWakeP bool) { _g_ := getg() top: _p_ := _g_.m.p.ptr() ... // 忽略 gc 相关  // local runq \tif gp, inheritTime := runqget(_p_); gp != nil { return gp, inheritTime, false } // global runq \tif sched.runqsize != 0 { lock(\u0026amp;sched.lock) gp := globrunqget(_p_, 0) unlock(\u0026amp;sched.lock) if gp != nil { return gp, false, false } } ... // 忽略网络轮询器相关  // Spinning Ms：窃取其他 Ps 的工作。  // 限制旋转 Ms 的数量为忙碌 Ps 数量的一半。  // 这是防止 CPU 消耗过多的必要条件  // GOMAXPROCS\u0026gt;\u0026gt;1 但程序并行度低。 \tprocs := uint32(gomaxprocs) if _g_.m.spinning || 2*atomic.Load(\u0026amp;sched.nmspinning) \u0026lt; procs-atomic.Load(\u0026amp;sched.npidle) { if !_g_.m.spinning { _g_.m.spinning = true atomic.Xadd(\u0026amp;sched.nmspinning, 1) } gp, inheritTime, tnow, w, newWork := stealWork(now) now = tnow if gp != nil { // Successfully stole. \treturn gp, inheritTime, false } if newWork { // There may be new timer or GC work; restart to \t// discover. \tgoto top } if w != 0 \u0026amp;\u0026amp; (pollUntil == 0 || w \u0026lt; pollUntil) { // Earlier timer to wait for. \tpollUntil = w } } ... // 实在无事可做，drop P } 阻塞与抢占  阻塞是指当前的G因为一些操作，如系统调用，需要等待，此时M未被利用情况\n抢占是指一个G在没有阻塞情况下执行占用M的时间过长，其他G得不到执行，其他G需要抢占M来获得执行\n 抢占式调度  操作系统的调度是时间片，而go没有该设计，go是通过sysmon的监控程序来实现的。\n   sysmon: src/runtime/proc.go:5134\n// 不需要绑定P运行 func sysmon() { ... for { // 20us - 10ms 唤醒一次  usleep(delay) ... // 重新获取在系统调用中阻塞的 P  // 并抢占长时间运行的 G \tif retake(now) != 0 { idle = 0 } else { idle++ } ... } } func retake(now int64) uint32 { ... s := _p_.status sysretake := false if s == _Prunning || s == _Psyscall { // 如果P运行时间过长则抢占 \tt := int64(_p_.schedtick) if int64(pd.schedtick) != t { pd.schedtick = uint32(t) pd.schedwhen = now } else if pd.schedwhen+forcePreemptNS \u0026lt;= now { preemptone(_p_) // 在 goroutine 上标记 gp.preempt = true \t// In case of syscall, preemptone() doesn\u0026#39;t \t// work, because there is no M wired to P. \tsysretake = true } } ... }   阻塞情况下的调度   syscall\n如果G被阻塞在某个system call操作上，那么不光G会阻塞，执行该G的M也会解绑P(实质是被sysmon抢走了)，与G一起进入sleep状态。如果此时有idle的M，则P与该M绑定继续执行其他G；如果没有idle M，但仍然有其他G要去执行，那么就会创建一个新M。当阻塞在syscall上的G完成syscall调用后，G会去尝试获取一个可用的P，如果没有可用的P，那么G会被标记为runnable，之前的那个sleep的M将再次进入sleep。\n  channel 或 network I/O\n如果G被阻塞在某个channel操作或network I/O操作上时，G会被放置到某个wait队列中，而M会尝试运行下一个runnable的G；如果此时没有runnable的G供m运行，那么m将解绑P，并进入sleep状态。当I/O available或channel操作完成，在wait队列中的G会被唤醒，标记为runnable，放入到某P的队列中，绑定一个M继续执行。\n  其他的调度方式  NUMA调度提议  ###调度器在Go中如何运行\n要理解调度器，仅仅知道G-P-M还不够，还需要了解完整的调度流程，调度器的初始化、goroutine的添加等等，这一块会再去读一读源码，理解一下。\n在工作中的使用  工作中总是充满了CURD，我常常迷惑于了解了这些知识有什么作用，我又该如何应用。\n   了解调度，我们才能知道该如何在应用中去使用 goroutine，goroutine 虽然轻量，但也不是越多越好。\n  遇到一些问题时，我们可以通过查看调度来思考代码的优化方案。\n  如何查看go调度器：通过GODEBUG运行时环境变量的schedtrace=1000参数，可以每隔1000ms查看一次调度器状态。\nGODEBUG=schedtrace=1000 ./main 打印 SCHED 1007ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=5 runqueue=0 [0 0 0 0] SCHED 2011ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=5 runqueue=0 [0 0 0 0] 参数含义 gomaxprocs: P的数量； idleprocs: 处于idle状态的P的数量；通过gomaxprocs和idleprocs的差值，我们就可知道执行go代码的P的数量； threads: os threads的数量，包含scheduler使用的m数量，加上runtime自用的类似sysmon这样的thread的数量； spinningthreads: 处于自旋状态的os thread数量； idlethread: 处于idle状态的os thread的数量； runqueue： go scheduler全局队列中G的数量； [0 0 0 0]: 分别为4个P的local queue中的G的数量。   总结  go 调度经历过几个版本，很巧妙的地方就是中间层P的抽象，很多设计的核心都很简单，但是其最迷人的地方就是抽象。 很多文章都讲过G-P-M调度，内容其实大同小异，在写这篇博文的时候，去翻看了源码，其实这些东西都在代码里，且有很好的注释。  相关资料   《Go 语言设计与实现》—— 左神\n  Go 调度模型——wudaijun\u0026rsquo;s blog\n  ","permalink":"https://Phil-zyx.github.io/posts/%E5%AF%B9go%E8%B0%83%E5%BA%A6%E7%9A%84%E6%B5%85%E8%AF%BB/","summary":"go语言为什么能变的如此受欢迎，很大一个原因是其原生支持高并发，而这核心来自goroutine的设计，而对goroutine的管理则离不开go的调度器。\n调度的定义  要理解调度，就必要先理解操作系统、进程、线程等调度的基本概念。\n  操作系统：一种计算机程序，管理硬件与软件资源，计算机系统的\u0026quot;底层软件\u0026quot;，如windows,macOS,Linux 进程：操作系统下程序运行单位，有独立的内存，由内核调度 线程：操作系统调度最小单元，一般属于进程，共享进程的内存与资源，由内核调度（比进程轻量） 协程：用户级线程，不由内核调度，通过程序员显示的调度（比线程轻量） 调度：调度本质上就是一个资源分配算法。  Go 调度设计  goroutine 和线程的关系即一个main函数创建一个操作线程——主线程，之后会由go的调度模型来负责创建和管理 goroutine 分配到具体哪个线程.\n 历史  最简单的调度器（Go 0.x）：单线程 G-M：缺陷是程序只能存在一个活跃线程 改进为多线程（Go 1.0）：G-M：互斥锁带来的开销 进阶版本（Go 1.2 至今）：G-P-M：多了一层P抽象  G-P-M   定义：src/runtime/runtime2.go\n  G：goroutine，需要绑定一个 m 来运行\ntype g struct { ... m *m // current m; offset known to arm liblink  preempt bool // 抢占标记  stackguard0 uintptr //  ... }   P：processor, a resource that is required to execute Go code.","title":"对go调度的浅读"},{"content":" 最近工作上做了一些关于跨服玩法的内容，对于 RPC 通信实现这块做下学习笔记整理。\n 分布式架构 当下的大环境下，服务器架构基本都是分布式架构。分布式架构带来的最大好处在于服务扩展，我们 SLG 游戏服务器从游戏特性上来说，符合小服架构（一个服即一个生态），这样从分布式架构的设计理念，按功能划分，网关、支付、战场（这里不是指单服的战斗要实现一个节点，而是一些副本玩法，跨服玩法等设计的）、第三方等，这样的每个 server 我们称之为一个节点（Node）。\nRPC RPC:允许运行于一台计算机的程序调用另一个计算机的程序。RPC是一种服务器-客户端（Client/Server）模式。\nRPC 的核心概念即调用远程服务就像调用本地的一个函数一样简单。\n通过原理我们知道 RPC 需要实现的几个点:\n 通信：在两个 server 之间建立连接 寻址：如何定位需要调用 x-Server 序列化：两个 server 之间是网络通信，那么二进制传输就需要序列化  一些常用的框架（轮子必然是有的）：\n gRPC: 谷歌开源 RPC 框架，基于 HTTP/2 协议通信和 ProtoBuf 序列化协议 Thrift: Apache 旗下，基于 Facebook 的 RPC 框架开发 JsonRPC: 无状态、轻量级，基于 json 序列化  框架选择：两个项目，早期的一个选择 thrift （当时 gRPC 才开源初期），另一个选择了 gRPC ，对比来说，两者在使用上区别不是很大，但是 gRPC 能拥有良好的文档，更加简洁和拥有广泛使用的 ProtoBuf，而 thrift 的大优势是支持多语言。选择根据项目自身的特性来，对于我们项目，文档和简洁比较重要。（技术选型还得是项目初始大佬们的选择:joy:）\n节点间通信 如上，RPC 框架选择 gRPC，基于此，整个通信流程：\nclient -\u0026gt; gateway -\u0026gt; game server -\u0026gt; other server -\u0026gt; 处理后返回\n游戏服务器一般选择长连接，因为游戏特性：交互频繁，数据量大。RPC 当然也有这种特性，所以 gRPC 也支持一次调用一次创建和流式（stream）调用两种方式，这个根据业务的情况进行处理。client 与 game server 的通信采用了双向 steam 方式，client 通过和 gate 建立 tcp 连接（一个 agent），然后通过 LoginReq 来创建和 game server 的流式管道（中间还有玩家信息验证服交互，目标服务器 check 等操作 | 目标服的 connect 信息通过 etcd 获取， etcd 做服务发现和管理），每个 agent 本身会有一个 pipe mgr 来管理这些创建的管道，用于和不同的 server 之间进行消息收发。这样就建立起 client \u0026lt;—\u0026gt; game server 的通信连接。\n既然节点间的通信就是 client/server 的模式，那么 game server 和 battle server 之间的服务调用也就差别不大。以此为例，简述我们 gs 和 bs 之间的服务调用：\n 一次调用：gRPC Asyn Call 调用 bs 的服务器，通过异步回调返回执行的数据，并处理返还给 client steam: 每个 server 都有一个自己的 gate mgr 用于管理 RPC 消息通信和 agent data，首次调用 bs 服务时创建一个 steam 连接，后面调用直接 sendMsg 没有玩家 agent 的 stream 调用：每个 server 都创建一个 owner agent 并且在需要的时候和目标 server 之间建立一个 steam pipe，来完成多次调用  举例说明：\n我现在有个副本玩法，需要开房间实现 pvp：\n-\u0026gt; clientA 通过 loginBattleReq 创建和 bs 的 steam 连接，并且在 bs 开启一个房间\n-\u0026gt; clientB 通过 joinBattleReq 同样创建一个 stream 连接，加入到 A 的房间\n-\u0026gt; 然后 bs 房间业务逻辑执行，A vs B 战斗开始\n-\u0026gt; SLG 的一个特性，不同于 moba 游戏玩法，这里业务上可能多个玩家要持续一段时间 pvp 获得积分，在结束时，玩家可能已经不在线，steam 和 agent 也销毁了，结算信息传递给 gs 就需要通过 owner agent 来实现了。由此，一个完整的节点通信模型就实现了。\n总结  目前的这套架构实现比较简单，弱耦合单向依赖 gRPC call、强耦合双向依赖 stream，已经能满足当下的基本需求，其次在编码方面做了一些封装，对于开发人员来说比较方便。 当需求变化伴随节点细分变多，耦合变重，那么网络拓扑也会变成一个问题，这种情况下的 steam 就不能很好的胜任。  ","permalink":"https://Phil-zyx.github.io/posts/%E6%BC%AB%E8%B0%88%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%8A%82%E7%82%B9%E9%80%9A%E4%BF%A1/","summary":"最近工作上做了一些关于跨服玩法的内容，对于 RPC 通信实现这块做下学习笔记整理。\n 分布式架构 当下的大环境下，服务器架构基本都是分布式架构。分布式架构带来的最大好处在于服务扩展，我们 SLG 游戏服务器从游戏特性上来说，符合小服架构（一个服即一个生态），这样从分布式架构的设计理念，按功能划分，网关、支付、战场（这里不是指单服的战斗要实现一个节点，而是一些副本玩法，跨服玩法等设计的）、第三方等，这样的每个 server 我们称之为一个节点（Node）。\nRPC RPC:允许运行于一台计算机的程序调用另一个计算机的程序。RPC是一种服务器-客户端（Client/Server）模式。\nRPC 的核心概念即调用远程服务就像调用本地的一个函数一样简单。\n通过原理我们知道 RPC 需要实现的几个点:\n 通信：在两个 server 之间建立连接 寻址：如何定位需要调用 x-Server 序列化：两个 server 之间是网络通信，那么二进制传输就需要序列化  一些常用的框架（轮子必然是有的）：\n gRPC: 谷歌开源 RPC 框架，基于 HTTP/2 协议通信和 ProtoBuf 序列化协议 Thrift: Apache 旗下，基于 Facebook 的 RPC 框架开发 JsonRPC: 无状态、轻量级，基于 json 序列化  框架选择：两个项目，早期的一个选择 thrift （当时 gRPC 才开源初期），另一个选择了 gRPC ，对比来说，两者在使用上区别不是很大，但是 gRPC 能拥有良好的文档，更加简洁和拥有广泛使用的 ProtoBuf，而 thrift 的大优势是支持多语言。选择根据项目自身的特性来，对于我们项目，文档和简洁比较重要。（技术选型还得是项目初始大佬们的选择:joy:）\n节点间通信 如上，RPC 框架选择 gRPC，基于此，整个通信流程：\nclient -\u0026gt; gateway -\u0026gt; game server -\u0026gt; other server -\u0026gt; 处理后返回","title":"漫谈游戏服务器节点通信"},{"content":" 题目：循环按序打印\u0026quot;dog\u0026quot;、\u0026ldquo;cat\u0026rdquo;、fish\u0026quot;，分别使用三个 goroutine.\n 拿到题目，感觉简单又不简单的样子，先动手写一个最简单的打印：\nfunc main() { times := 100 go func() { for i := 0; i\u0026lt;times; i++ { println(\u0026#34;dog\u0026#34;) println(\u0026#34;cat\u0026#34;) println(\u0026#34;fish\u0026#34;) } }() time.Sleep(100 * 1000) // 这时间我能算出来么，那用 channel 来接收吧 } 改进一下这让人无法预估的等待时间：使用 channel，在 goroutine 执行完之后通知主程序，巩固依稀 gorutine 和 channel 的基础知识：\n gorutine 是并发核心，main 函数也是一个 gorutine go func() {}() 匿名函数要注意参数传入 channel 通过 make 创建，make(chan typ) 需要声明好类型 channel 通过 \u0026lt;-ch ch \u0026lt;- data 来接收和发送信息 channel make(ch, int, 1 表示该 ch 是一个有1个数据缓冲的 chan，即在没有接收数据的情况下，第二条数据发送之后才会阻塞 func (ch chan \u0026lt;- int) 声明 ch 是一个单向 channel close后的 chan 依然可以接收缓冲通道的数据，但不可发送数据 select {case \u0026lt;- ch: xx} 处理不同消息  func main() { waitCh := make(chan struct{}, 1) times := 100 go func() { for i := 0; i \u0026lt; times; i++ { println(\u0026#34;dog\u0026#34;) println(\u0026#34;cat\u0026#34;) println(\u0026#34;fish\u0026#34;) } waitCh \u0026lt;- struct{}{} }() \u0026lt;-waitCh } waitCh 听起来怎么这么熟悉呢？go 本身在面对这些情况已经实现了一个工具类，sync 包中提供的基础原语： waitGroup 。巩固一下：\n 官方描述：一个 WaitGroup 对象可以等待一组协程结束 我们可以通过 sync.WaitGroup 将原本顺序执行的代码在多个 Goroutine 中并发执行，加快程序处理的速度。 该类暴露三个接口：add wait done 废话别说，show me the code 🙂  func main() { wg := sync.WaitGroup{} times := 100 wg.Add(1) // 协程数 \tgo func() { for i := 0; i \u0026lt; times; i++ { println(\u0026#34;dog\u0026#34;) println(\u0026#34;cat\u0026#34;) println(\u0026#34;fish\u0026#34;) } wg.Done() // 协程执行完毕，一般复杂业务会有容错，确保执行： defer wg.Done() \t}() wg.Wait() } 实现三个直接打印的 goroutine 必然不能保证有序，那就必须在 goroutine 间通信，cha -\u0026gt; chb -\u0026gt; chc-\u0026gt;cha 循环触发则可以实现该功能。\nfunc main() { wg := sync.WaitGroup{} wg.Add(3) dogCh := make(chan struct{}, 1) catCh := make(chan struct{}, 1) fishCh := make(chan struct{}, 1) times := 10 dogCounter, catCounter, fishCounter := 0, 0, 0 go PrintTheVal(dogCh, catCh, dogCounter, times, \u0026amp;wg, \u0026#34;dog\u0026#34;) // \u0026amp;wg 需要取地址 \tgo PrintTheVal(catCh, fishCh, catCounter, times, \u0026amp;wg, \u0026#34;cat\u0026#34;) go PrintTheVal(fishCh, dogCh, fishCounter, times, \u0026amp;wg, \u0026#34;fish\u0026#34;) dogCh \u0026lt;- struct{}{} wg.Wait() } func PrintTheVal(selfCh, toCh chan struct{}, counter, max int, wg *sync.WaitGroup, val string) { for { \u0026lt;- selfCh toCh \u0026lt;- struct{}{} if counter \u0026gt;= max { wg.Done() return } println(val) counter++ } } 总结  通过简单的题目能快速理解基础语法，也能在实现简单题目中发现不足和巩固基础。 发散思维：其他同步原语的使用？  ","permalink":"https://Phil-zyx.github.io/posts/%E4%B8%80%E9%81%93go%E7%BC%96%E7%A8%8B%E9%A2%98%E7%9A%84%E5%8F%8D%E6%80%9D/","summary":"题目：循环按序打印\u0026quot;dog\u0026quot;、\u0026ldquo;cat\u0026rdquo;、fish\u0026quot;，分别使用三个 goroutine.\n 拿到题目，感觉简单又不简单的样子，先动手写一个最简单的打印：\nfunc main() { times := 100 go func() { for i := 0; i\u0026lt;times; i++ { println(\u0026#34;dog\u0026#34;) println(\u0026#34;cat\u0026#34;) println(\u0026#34;fish\u0026#34;) } }() time.Sleep(100 * 1000) // 这时间我能算出来么，那用 channel 来接收吧 } 改进一下这让人无法预估的等待时间：使用 channel，在 goroutine 执行完之后通知主程序，巩固依稀 gorutine 和 channel 的基础知识：\n gorutine 是并发核心，main 函数也是一个 gorutine go func() {}() 匿名函数要注意参数传入 channel 通过 make 创建，make(chan typ) 需要声明好类型 channel 通过 \u0026lt;-ch ch \u0026lt;- data 来接收和发送信息 channel make(ch, int, 1 表示该 ch 是一个有1个数据缓冲的 chan，即在没有接收数据的情况下，第二条数据发送之后才会阻塞 func (ch chan \u0026lt;- int) 声明 ch 是一个单向 channel close后的 chan 依然可以接收缓冲通道的数据，但不可发送数据 select {case \u0026lt;- ch: xx} 处理不同消息  func main() { waitCh := make(chan struct{}, 1) times := 100 go func() { for i := 0; i \u0026lt; times; i++ { println(\u0026#34;dog\u0026#34;) println(\u0026#34;cat\u0026#34;) println(\u0026#34;fish\u0026#34;) } waitCh \u0026lt;- struct{}{} }() \u0026lt;-waitCh } waitCh 听起来怎么这么熟悉呢？go 本身在面对这些情况已经实现了一个工具类，sync 包中提供的基础原语： waitGroup 。巩固一下：","title":"一道GO编程题的反思"},{"content":"2020 即将过去，这一年最大的总结就是：什么目标也没有完成。\n","permalink":"https://Phil-zyx.github.io/posts/summary2020/","summary":"2020 即将过去，这一年最大的总结就是：什么目标也没有完成。","title":"2020 年终总结"},{"content":" 目前从事游戏服务器开发 Gopher 游戏爱好者  最后留个\n QQ：1757163340 Email：zhouyaoxux@gmail.com   法律与支持  服务条款 隐私权政策 支持与帮助  ","permalink":"https://Phil-zyx.github.io/aboutme/","summary":"aboutme","title":"About Me"},{"content":"支持与帮助中心 欢迎来到我们的支持与帮助中心。我们致力于为您提供最佳的用户体验和及时的支持服务。\n常见问题 (FAQ) 产品使用 如何开始使用我们的产品？ 下载并安装我们的应用后，您可以通过创建账户或直接以访客身份使用。首次启动应用时，会有引导教程帮助您了解基本功能和操作方式。\n我忘记了密码怎么办？ 您可以在登录页面点击\u0026quot;忘记密码\u0026quot;链接，按照提示进行密码重置。\n如何更新我的账户信息？ 登录后，进入\u0026quot;个人设置\u0026quot;或\u0026quot;账户管理\u0026quot;页面进行信息更新。\n账单与支付 支持哪些支付方式？ 我们目前支持信用卡、PayPal等多种支付方式。\n如何查看我的订阅状态？ 登录账户后，在\u0026quot;订阅\u0026quot;或\u0026quot;账单\u0026quot;部分可以查看您的订阅状态。\n如何获取发票？ 您可以在\u0026quot;账单历史\u0026quot;中下载电子发票，或联系我们的客服团队获取帮助。\n技术问题 应用无法正常运行怎么办？  确保您使用的是最新版本 尝试重启应用 检查您的网络连接 清除应用缓存  数据同步问题 如果遇到数据同步问题，请确保您的设备已连接到互联网，并尝试手动刷新应用。\n联系我们 如果您没有在上面找到所需的帮助，请通过以下方式联系我们：\n电子邮件支持 发送邮件至 zhouyaoxux@gmail.com，我们会在24小时内回复您。\n社交媒体  Twitter: @Fancy_paul3 知乎: 个人主页  反馈与建议 我们非常重视用户的反馈和建议。如果您有任何想法或建议，请随时与我们分享。您的意见将帮助我们不断改进产品和服务。\n 我们的支持团队工作时间：周一至周五 9:00-18:00 (GMT+8)\n","permalink":"https://Phil-zyx.github.io/support/","summary":"支持与帮助","title":"支持与帮助"},{"content":"服务条款 最后更新日期: 2025-02-25\n1. 接受条款 欢迎使用我们的服务。通过访问或使用我们的产品、服务或内容，您同意受本服务条款的约束。\n2. 服务描述 我们提供的服务旨在为用户提供高质量的移动应用和数字内容。我们保留随时修改、暂停或终止服务的权利，恕不另行通知。\n3. 用户账户 如果您创建账户，您需要提供准确、完整和最新的信息。您有责任保护您的账户安全，并对账户下发生的所有活动负责。\n4. 用户行为 您同意不会:\n 违反任何适用法律或法规 侵犯他人的知识产权或其他权利 传播恶意软件或有害代码 干扰服务的正常运行 未经授权访问我们的系统或网络  5. 内容和知识产权 我们的服务和内容受版权、商标和其他知识产权法律保护。除非明确授权，否则您不得复制、修改、分发或创建衍生作品。\n6. 免责声明 我们的服务按\u0026quot;原样\u0026quot;提供，不提供任何明示或暗示的保证。\n7. 责任限制 在法律允许的最大范围内，我们对任何直接、间接、附带、特殊、后果性或惩罚性损害不承担责任。\n8. 条款修改 我们保留随时修改这些条款的权利。修改后的条款将在我们的网站上发布时生效。继续使用我们的服务即表示您接受修改后的条款。\n9. 适用法律 本条款受中华人民共和国法律管辖，不考虑法律冲突原则。\n10. 联系我们 如果您对这些条款有任何疑问，请通过以下方式联系我们:\n 电子邮件: zhouyaoxux@gmail.com  ","permalink":"https://Phil-zyx.github.io/terms/","summary":"服务条款","title":"服务条款"},{"content":"隐私权政策 最后更新日期: 2025-02-25\n本隐私权政策描述了我们如何收集、使用、处理和保护您的个人信息。我们重视您的隐私，并致力于保护您的个人数据。\n1. 信息收集 1.1 您直接提供的信息 当您使用我们的服务时，我们可能会收集以下类型的信息:\n 个人识别信息(如姓名、电子邮件地址、电话号码) 账户信息(如用户名和密码) 支付信息(如信用卡详情，仅用于处理交易) 您与我们的通信记录  1.2 自动收集的信息 当您访问我们的服务时，我们可能会自动收集某些信息，包括:\n 设备信息(如设备类型、操作系统) 日志数据(如IP地址、访问时间) 使用数据(如您如何使用我们的服务) Cookie和类似技术收集的信息  2. 信息使用 我们使用收集的信息用于:\n 提供、维护和改进我们的服务 处理交易和发送相关信息 响应您的请求和提供客户支持 发送技术通知、更新和安全警报 监控服务的使用情况 检测、预防和解决技术问题  3. 信息共享 我们不会出售您的个人信息。我们可能在以下情况下共享您的信息:\n 经您同意 与我们的服务提供商和合作伙伴共享，以帮助我们提供服务 遵守法律要求 保护我们的权利和财产  4. 数据安全 我们采取合理的措施保护您的个人信息不被未经授权的访问、使用或披露。然而，没有任何互联网传输或电子存储方法是100%安全的。\n5. 您的权利 根据适用的数据保护法律，您可能拥有以下权利:\n 访问您的个人数据 更正不准确的数据 删除您的数据 限制或反对处理 数据可携带性  6. 儿童隐私 我们的服务不面向13岁以下的儿童。我们不会故意收集13岁以下儿童的个人信息。\n7. 第三方链接 我们的服务可能包含指向第三方网站的链接。我们对这些网站的隐私政策或内容不负责任。\n8. 政策变更 我们可能会不时更新本隐私政策。我们会通过在网站上发布新版本来通知您任何变更。\n9. 联系我们 如果您对本隐私政策有任何疑问，请通过以下方式联系我们:\n 电子邮件: zhouyaoxux@gmail.com  ","permalink":"https://Phil-zyx.github.io/privacy/","summary":"隐私权政策","title":"隐私权政策"}]